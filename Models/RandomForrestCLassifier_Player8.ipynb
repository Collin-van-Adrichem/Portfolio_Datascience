{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b5b9306",
   "metadata": {},
   "source": [
    "# Libraries\n",
    "\n",
    "Import your libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6767672b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from scipy import signal\n",
    "import statistics as cal\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, plot_confusion_matrix, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b053ddc",
   "metadata": {},
   "source": [
    "# Preparing Data\n",
    "\n",
    "Split the Dataframe in chunks van n/100 seconden. Combine to 1 dataframe. With Sum,Div and Action split into Train and Valid/Test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcca66e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dataloader(CsvFile, ChunkSize, ChunkOverlap, OperationList):\n",
    "#CsvFile = put in the filename(as string) example : matrix_player_15_game_2_quartersplit.csv\n",
    "#ChunkSize = put in the size you want the chunks to be (in seconds) example: 1\n",
    "#ChunkOverlap = the size you want the chunks to overlap (in seconds) example: 0.5\n",
    "#Operationlist = input dataframe of names with operations that u want to make changes to. example:\n",
    "                                #Operationlist = pd.DataFrame({'frAcc':['cal.mean'], 'wheelRotationalSpeedX':['cal.mea']})\n",
    "\n",
    "\n",
    "#load in csv file\n",
    "    df = pd.read_csv(CsvFile)\n",
    "\n",
    "    chunks = [df[i:i+ChunkSize] for i in range(0,df.shape[0],ChunkOverlap)]\n",
    "\n",
    "    frames = []\n",
    "\n",
    "    for chunk in chunks:\n",
    "        chunk = chunk.drop(columns=['Unnamed: 0'])\n",
    "        frames.append(chunk)\n",
    "\n",
    "        \n",
    "    df_end =[]\n",
    "    \n",
    "    for frame in frames:\n",
    "        if len(frame) == 100:\n",
    "            result = [] #Reset the result array\n",
    "            for column in list(frame.columns):\n",
    "        \n",
    "                if column in OperationList: #Check if column is in namelist\n",
    "            \n",
    "                    if OperationList[str(column)].values == 'cal.mean': #You can at more function if you want\n",
    "                        X = cal.mean(frame[str(column)].tolist()) #Calculate mean of all columns named in namelist with operation cal.mean\n",
    "            \n",
    "                    else: #If the given operations isn't cal.mean\n",
    "                        frame[str(column)] = [abs(ele) for ele in frame[str(column)]] #Get absolute value of all elements in list\n",
    "                        X = max(frame[str(column)].tolist()) #Get single max value from list \n",
    "       \n",
    "                else:\n",
    "                    frame[str(column)] = [abs(ele) for ele in frame[str(column)]] #Get absolute value of all elements in list\n",
    "                    X = max(frame[str(column)].tolist()) #Get single max value from list\n",
    "            \n",
    "                result.append(X) #Append results to list\n",
    "        \n",
    "            df_end.append(result) #Append all results into one big list\n",
    "    \n",
    "    df_end = pd.DataFrame(df_end, columns = list(frame.columns)) #Convert list to df\n",
    "    return(df_end)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9e9f42",
   "metadata": {},
   "source": [
    "# Importing Data\n",
    "\n",
    "Import the CSV file with Actions, Sum and Div as a Dataframe called df. Fill the empty values of Action with 0. \n",
    "Replace NaN values with 0. Delete first 100 rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e06fbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "OperationList = [{ 'wheelRotationalSpeedX' : ['Cal.mean']}]\n",
    "df_train = pd.read_csv('Player_15_Game2_Sprints_Q1234.csv')\n",
    "df_test = Dataloader('matrix_Player_8_game_2_QuarterSplit.csv', 100, 50, OperationList)\n",
    "#print(Dataloader('matrix_Player_15_game_2_QuarterSplit.csv', 100, 50, OperationList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14573311",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['wheelRotationalSpeedXDiff'] = np.insert(np.diff(df_train.wheelRotationalSpeedX,n=1),0,0)\n",
    "df_train['Sum_WheelX_FrameZ'] = df_train.wheelRotationalSpeedX + df_train.frameRotationalSpeedZ\n",
    "\n",
    "df_test['wheelRotationalSpeedXDiff'] = np.insert(np.diff(df_test.wheelRotationalSpeedX,n=1),0,0)\n",
    "df_test['Sum_WheelX_FrameZ'] = df_test.wheelRotationalSpeedX + df_test.frameRotationalSpeedZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe955925",
   "metadata": {},
   "outputs": [],
   "source": [
    "Order = 5\n",
    "cutoff_freq = 1.5\n",
    "sampling_freq = 100\n",
    "sampling_duration = len(df_test)\n",
    "\n",
    "normalized_cutoff_freq = 2 * cutoff_freq / sampling_freq\n",
    "numerator_coeffs, denominator_coeffs = signal.butter(Order, normalized_cutoff_freq)\n",
    "df_test['Filt_WheelX'] = signal.lfilter(numerator_coeffs, denominator_coeffs, df_test.wheelRotationalSpeedX)\n",
    "df_test['Filt_FrameZ'] = signal.lfilter(numerator_coeffs, denominator_coeffs, df_test.frameRotationalSpeedZ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65c9383",
   "metadata": {},
   "source": [
    "## Split data set in train and test\n",
    "below are columns used to identify the best features for the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c214ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split chunk data into train test validate (with colum [sum and Div] as input, and action as output)\n",
    "\n",
    "train = df_train\n",
    "test = df_test\n",
    "\n",
    "column1 = ['frSpeed']\n",
    "column2 = ['frSpeed','frAcc']\n",
    "column3 = ['frSpeed','frAcc','wheelRotationalSpeedXDiff']\n",
    "column4 = ['frSpeed','frAcc','wheelRotationalSpeedXDiff','frRoAcc' ]\n",
    "column5 = ['frSpeed','frAcc','wheelRotationalSpeedXDiff','frRoAcc','frameRotationalSpeedZ' ]\n",
    "column6 = ['frSpeed','frAcc','wheelRotationalSpeedXDiff','frRoAcc','frameRotationalSpeedZ','wheelRotationalSpeedX' ]\n",
    "column7 = ['timeLine','frSpeed','frAcc','wheelRotationalSpeedXDiff','frRoAcc','frameRotationalSpeedZ','wheelRotationalSpeedX','Filt_FrameZ' ]\n",
    "column8 = ['frSpeed','frAcc','wheelRotationalSpeedXDiff','frRoAcc','frameRotationalSpeedZ','wheelRotationalSpeedX','Filt_FrameZ','Filt_WheelX' ]\n",
    "column9 = ['wheelRotationalSpeedXDiff']\n",
    "column10 = ['wheelRotationalSpeedXDiff','Filt_WheelX']\n",
    "column11 = ['wheelRotationalSpeedXDiff','Filt_WheelX','Filt_FrameZ']\n",
    "column12 = ['wheelRotationalSpeedXDiff','frSpeed','frAcc','frameRotationalSpeedZ']\n",
    "column13 = ['frAcc','frSpeed','frameRotationalSpeedZ','Sum_WheelX_FrameZ','wheelRotationalSpeedXDiff']\n",
    "\n",
    "\n",
    "X_train = train[column7]\n",
    "\n",
    "y_train = train[['Action']]\n",
    "\n",
    "\n",
    "X_test = test[column7]\n",
    "\n",
    "#y_test = test[['Action']]\n",
    "\n",
    "#y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0343e39a",
   "metadata": {},
   "source": [
    "# Gridsearch toepassen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43ab3334",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35958/3382710434.py:10: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  tree = tree.fit(X_train,y_train)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tree_model_2 =  RandomForestClassifier(class_weight='balanced',n_jobs = 10, random_state = 6)\n",
    "\n",
    "\n",
    "param_grid_model_2 = {'n_estimators': [100, 200, 500,800], 'max_depth': [10,20,50] ,  'min_samples_leaf': [1,2,5,8,10] } \n",
    "\n",
    "\n",
    "\n",
    "#tree = GridSearchCV(tree_model_2,param_grid_model_2)\n",
    "tree = RandomForestClassifier(class_weight='balanced',n_jobs = 10, random_state = 6, max_depth = 10, min_samples_leaf = 8, n_estimators = 100)\n",
    "tree = tree.fit(X_train,y_train)\n",
    "#print(tree.best_params_)\n",
    "#print(tree.best_score_)\n",
    "#print(\"Test accuracy of best grid search hypers:\", tree.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10466c1",
   "metadata": {},
   "source": [
    "# Export Data\n",
    "\n",
    "Export the results in CSV format. Layout = Time,Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb695bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test['Action'] = tree.predict(X_test)\n",
    "#df_results = pd.DataFrame(X_test)\n",
    "#df_results.to_csv('Sprint_results_Player8_Game2_randomforest.csv')\n",
    "#df_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
